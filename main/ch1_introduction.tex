\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

With the advent and rapid advancement in the fields of electronics and computer science, computers are nowadays expected to understand and be aware of the world around us. A lot of research has been done on electronic devices that can perceive the context and guide the user of the device based on the context. Navigation assistance, for example is such an application that is already a part of our daily lives. But the context awareness is limited in this case. Furthermore, context information obtained by the devices through visual information using sensors such as camera could be easily prone to errors due to physical limitations, for example, even a  slight loss of sight in the process could lead to significant failures. 

Audio information, which is arguably more robust than visual information, can also provide contextual information and it has been extensively researched by the branch of computer science, known as audio information retrieval. It is a sub-field of multimedia information retrieval system in which audio signals such as speech, music, audio events, etc. are of specific interest. Audio information retrieval applications such as speech recognition, speaker identification, acoustic scene classification, audio event detection, etc. involve various machine learning models to give a desired performance. These machine learning models used for audio data have a huge potential of research and many of these are already used and have produced promising results.

Audio Event Detection is one of the several sub-fields of audio information retrieval. There are various interpretations of the concept of an audio event in the literature. In \cite{chu2009environmental}, sound events are the ambient sounds in nature, winds on trees, sound of rain, etc. On the contrary, in \cite{tran2011sound}, sound events are all the audio events that are not solely based on music or speech signals. \cite{salamon2014dataset} presents a taxonomy defining various audio events. Hence, audio events are not precisely and uniquely defined in the literature and we understand that the choice of the kind of audio events depends on the problem statement or the application area that is being tackled. 

Getting good results from a machine learning model is largely based on the selection of input features. In audio event detection, traditionally used features are the mel-frequency cepstral coefficients(MFCC), linear predictive cepstral coefficients (LPCC) and log-frequency power coefficients (LFPC). Also, the most used machine learning models in this field are the Gaussian Mixture Models (GMM) and the Hidden Markov Models (HMM). Recently, however, neural networks also have been used in this field. We also use neural networks as our machine learning model.

In this thesis, we present an approach for tackling the problem of audio events detection using  neural networks. We also present some results and insights that we obtained by applying neural networks on three different kinds of audio datasets. The audio datasets are basically set of audio recordings which are labeled with one or many of the audio events from the pre-defined set of audio events. Also, for one of the datasets, we artificially augment the audio data i.e. generate new data from the existing data to improve the machine learning model performance. 

Neural networks are strong non-linear machine learning models composed of several layers, and each layer containing several units. Due to their ability to analyze complex, multidimensional data, they are useful for complicated systems which are difficult to be expressed in compact mathematical formulas. Moreover, as the number of hidden layers increase, the network is called deep. Usually, training a deep neural network is not as trivial as a shallow network. An additional unsupervised pre-training stage is almost always required for deep networks to be successful. Such pre-trained and subsequently trained networks are called Deep Belief Networks (DBN). Such deep networks are used in a variety of machine learning areas such as image classification, natural language processing, feature learning, dimensionality reduction and have given promising results. This is indeed a motivation for using DNN in areas such as audio events detection and classification. We have also implemented a DNN and a CNN (convolutional neural network) model for our problem.

This thesis is organized as follows. Chapter 1 briefly discusses the theoretical background on audio event detection, neural networks, related work in audio event detection, artificial data augmentation and finally an overview of the three different audio datasets used for the experiments. Chapter 2 discusses the different machine learning models that we implemented along with the neural networks. This chapter describes all the steps including pre-processing, feature extraction, data division, network structure used  and finally the network training methodology applied (in case of neural networks). This chapter also describes the artificial audio data augmentation experiments performed on one of the audio datasets.  Chapter 3 presents the results obtained in our work and we discuss the procedure for obtaining the results as well as the analysis of results. Finally, we conclude the findings under the conclusions section which is then followed by the references and appendices sections.